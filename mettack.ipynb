{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Adversarial Attacks on Graph Neural Networks via Meta Learning. ICLR 2019\n",
    "        https://openreview.net/pdf?id=Bylnx209YX\n",
    "    Author Tensorflow implementation:\n",
    "        https://github.com/danielzuegner/gnn-meta-attack\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "from base_attack import BaseAttack\n",
    "\n",
    "\n",
    "class BaseMeta(BaseAttack):\n",
    "    \"\"\"Abstract base class for meta attack. Adversarial Attacks on Graph Neural\n",
    "    Networks via Meta Learning, ICLR 2019,\n",
    "    https://openreview.net/pdf?id=Bylnx209YX\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        model to attack. Default `None`.\n",
    "    nnodes : int\n",
    "        number of nodes in the input graph\n",
    "    lambda_ : float\n",
    "        lambda_ is used to weight the two objectives in Eq. (10) in the paper.\n",
    "    feature_shape : tuple\n",
    "        shape of the input node features\n",
    "    attack_structure : bool\n",
    "        whether to attack graph structure\n",
    "    attack_features : bool\n",
    "        whether to attack node features\n",
    "    device: str\n",
    "        'cpu' or 'cuda'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model=None, nnodes=None, feature_shape=None, lambda_=0.5, attack_structure=True, attack_features=False, device='cpu'):\n",
    "\n",
    "        super(BaseMeta, self).__init__(model, nnodes, attack_structure, attack_features, device) \n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "        assert attack_features or attack_structure, 'attack_features or attack_structure cannot be both False'\n",
    "\n",
    "        self.modified_adj = None\n",
    "        self.modified_features = None\n",
    "\n",
    "        if attack_structure:\n",
    "            assert nnodes is not None, 'Please give nnodes='\n",
    "            self.adj_changes = Parameter(torch.FloatTensor(nnodes, nnodes))\n",
    "            self.adj_changes.data.fill_(0)\n",
    "\n",
    "        if attack_features:\n",
    "            assert feature_shape is not None, 'Please give feature_shape='\n",
    "            self.feature_changes = Parameter(torch.FloatTensor(feature_shape))\n",
    "            self.feature_changes.data.fill_(0)\n",
    "\n",
    "        self.with_relu = model.with_relu\n",
    "\n",
    "    def attack(self, adj, labels, n_perturbations):\n",
    "        pass\n",
    "\n",
    "    def get_modified_adj(self, ori_adj):\n",
    "        adj_changes_square = self.adj_changes - torch.diag(torch.diag(self.adj_changes, 0))\n",
    "        ind = np.diag_indices(self.adj_changes.shape[0])\n",
    "        adj_changes_symm = torch.clamp(adj_changes_square + torch.transpose(adj_changes_square, 1, 0), -1, 1)\n",
    "        modified_adj = adj_changes_symm + ori_adj\n",
    "        return modified_adj\n",
    "\n",
    "    def get_modified_features(self, ori_features):\n",
    "        return ori_features + self.feature_changes\n",
    "\n",
    "    def filter_potential_singletons(self, modified_adj):\n",
    "        \"\"\"\n",
    "        Computes a mask for entries potentially leading to singleton nodes, i.e. one of the two nodes corresponding to\n",
    "        the entry have degree 1 and there is an edge between the two nodes.\n",
    "        \"\"\"\n",
    "\n",
    "        degrees = modified_adj.sum(0)\n",
    "        degree_one = (degrees == 1)\n",
    "        resh = degree_one.repeat(modified_adj.shape[0], 1).float()\n",
    "        l_and = resh * modified_adj\n",
    "        logical_and_symmetric = l_and + l_and.t()\n",
    "        flat_mask = 1 - logical_and_symmetric\n",
    "        return flat_mask\n",
    "\n",
    "    def self_training_label(self, labels, idx_train):\n",
    "        # Predict the labels of the unlabeled nodes to use them for self-training.\n",
    "        output = self.surrogate.output\n",
    "        labels_self_training = output.argmax(1)\n",
    "        labels_self_training[idx_train] = labels[idx_train]\n",
    "        return labels_self_training\n",
    "\n",
    "\n",
    "    def log_likelihood_constraint(self, modified_adj, ori_adj, ll_cutoff):\n",
    "        \"\"\"\n",
    "        Computes a mask for entries that, if the edge corresponding to the entry is added/removed, would lead to the\n",
    "        log likelihood constraint to be violated.\n",
    "\n",
    "        Note that different data type (float, double) can effect the final results.\n",
    "        \"\"\"\n",
    "        t_d_min = torch.tensor(2.0).to(self.device)\n",
    "        t_possible_edges = np.array(np.triu(np.ones((self.nnodes, self.nnodes)), k=1).nonzero()).T\n",
    "        allowed_mask, current_ratio = utils.likelihood_ratio_filter(t_possible_edges,\n",
    "                                                                    modified_adj,\n",
    "                                                                    ori_adj, t_d_min,\n",
    "                                                                    ll_cutoff)\n",
    "        return allowed_mask, current_ratio\n",
    "\n",
    "    def get_adj_score(self, adj_grad, modified_adj, ori_adj, ll_constraint, ll_cutoff):\n",
    "        adj_meta_grad = adj_grad * (-2 * modified_adj + 1)\n",
    "        # Make sure that the minimum entry is 0.\n",
    "        adj_meta_grad -= adj_meta_grad.min()\n",
    "        # Filter self-loops\n",
    "        adj_meta_grad -= torch.diag(torch.diag(adj_meta_grad, 0))\n",
    "        # # Set entries to 0 that could lead to singleton nodes.\n",
    "        singleton_mask = self.filter_potential_singletons(modified_adj)\n",
    "        adj_meta_grad = adj_meta_grad *  singleton_mask\n",
    "\n",
    "        if ll_constraint:\n",
    "            allowed_mask, self.ll_ratio = self.log_likelihood_constraint(modified_adj, ori_adj, ll_cutoff)\n",
    "            allowed_mask = allowed_mask.to(self.device)\n",
    "            adj_meta_grad = adj_meta_grad * allowed_mask\n",
    "        return adj_meta_grad\n",
    "\n",
    "    def get_feature_score(self, feature_grad, modified_features):\n",
    "        feature_meta_grad = feature_grad * (-2 * modified_features + 1)\n",
    "        feature_meta_grad -= feature_meta_grad.min()\n",
    "        return feature_meta_grad\n",
    "\n",
    "\n",
    "class Metattack(BaseMeta):\n",
    "    \"\"\"Meta attack. Adversarial Attacks on Graph Neural Networks\n",
    "    via Meta Learning, ICLR 2019.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> from deeprobust.graph.data import Dataset\n",
    "    >>> from deeprobust.graph.defense import GCN\n",
    "    >>> from deeprobust.graph.global_attack import Metattack\n",
    "    >>> from deeprobust.graph.utils import preprocess\n",
    "    >>> data = Dataset(root='/tmp/', name='cora')\n",
    "    >>> adj, features, labels = data.adj, data.features, data.labels\n",
    "    >>> adj, features, labels = preprocess(adj, features, labels, preprocess_adj=False) # conver to tensor\n",
    "    >>> idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "    >>> idx_unlabeled = np.union1d(idx_val, idx_test)\n",
    "    >>> idx_unlabeled = np.union1d(idx_val, idx_test)\n",
    "    >>> # Setup Surrogate model\n",
    "    >>> surrogate = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                    nhid=16, dropout=0, with_relu=False, with_bias=False, device='cpu').to('cpu')\n",
    "    >>> surrogate.fit(features, adj, labels, idx_train, idx_val, patience=30)\n",
    "    >>> # Setup Attack Model\n",
    "    >>> model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "            attack_structure=True, attack_features=False, device='cpu', lambda_=0).to('cpu')\n",
    "    >>> # Attack\n",
    "    >>> model.attack(features, adj, labels, idx_train, idx_unlabeled, n_perturbations=10, ll_constraint=False)\n",
    "    >>> modified_adj = model.modified_adj\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, nnodes, feature_shape=None, attack_structure=True, attack_features=False, device='cpu', with_bias=False, lambda_=0.5, train_iters=100, lr=0.1, momentum=0.9):\n",
    "\n",
    "        super(Metattack, self).__init__(model, nnodes, feature_shape, lambda_, attack_structure, attack_features, device)\n",
    "        self.momentum = momentum\n",
    "        self.lr = lr\n",
    "        self.train_iters = train_iters\n",
    "        self.with_bias = with_bias\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.w_velocities = []\n",
    "        self.b_velocities = []\n",
    "\n",
    "        self.hidden_sizes = self.surrogate.hidden_sizes\n",
    "        self.nfeat = self.surrogate.nfeat\n",
    "        self.nclass = self.surrogate.nclass\n",
    "\n",
    "        previous_size = self.nfeat\n",
    "        for ix, nhid in enumerate(self.hidden_sizes):\n",
    "            weight = Parameter(torch.FloatTensor(previous_size, nhid).to(device))\n",
    "            w_velocity = torch.zeros(weight.shape).to(device)\n",
    "            self.weights.append(weight)\n",
    "            self.w_velocities.append(w_velocity)\n",
    "\n",
    "            if self.with_bias:\n",
    "                bias = Parameter(torch.FloatTensor(nhid).to(device))\n",
    "                b_velocity = torch.zeros(bias.shape).to(device)\n",
    "                self.biases.append(bias)\n",
    "                self.b_velocities.append(b_velocity)\n",
    "\n",
    "            previous_size = nhid\n",
    "\n",
    "        output_weight = Parameter(torch.FloatTensor(previous_size, self.nclass).to(device))\n",
    "        output_w_velocity = torch.zeros(output_weight.shape).to(device)\n",
    "        self.weights.append(output_weight)\n",
    "        self.w_velocities.append(output_w_velocity)\n",
    "\n",
    "        if self.with_bias:\n",
    "            output_bias = Parameter(torch.FloatTensor(self.nclass).to(device))\n",
    "            output_b_velocity = torch.zeros(output_bias.shape).to(device)\n",
    "            self.biases.append(output_bias)\n",
    "            self.b_velocities.append(output_b_velocity)\n",
    "\n",
    "        self._initialize()\n",
    "\n",
    "    def _initialize(self):\n",
    "        for w, v in zip(self.weights, self.w_velocities):\n",
    "            stdv = 1. / math.sqrt(w.size(1))\n",
    "            w.data.uniform_(-stdv, stdv)\n",
    "            v.data.fill_(0)\n",
    "\n",
    "        if self.with_bias:\n",
    "            for b, v in zip(self.biases, self.b_velocities):\n",
    "                stdv = 1. / math.sqrt(w.size(1))\n",
    "                b.data.uniform_(-stdv, stdv)\n",
    "                v.data.fill_(0)\n",
    "\n",
    "    def inner_train(self, features, adj_norm, idx_train, idx_unlabeled, labels):\n",
    "        self._initialize()\n",
    "\n",
    "        for ix in range(len(self.hidden_sizes) + 1):\n",
    "            self.weights[ix] = self.weights[ix].detach()\n",
    "            self.weights[ix].requires_grad = True\n",
    "            self.w_velocities[ix] = self.w_velocities[ix].detach()\n",
    "            self.w_velocities[ix].requires_grad = True\n",
    "\n",
    "            if self.with_bias:\n",
    "                self.biases[ix] = self.biases[ix].detach()\n",
    "                self.biases[ix].requires_grad = True\n",
    "                self.b_velocities[ix] = self.b_velocities[ix].detach()\n",
    "                self.b_velocities[ix].requires_grad = True\n",
    "\n",
    "        for j in range(self.train_iters):\n",
    "            hidden = features\n",
    "            for ix, w in enumerate(self.weights):\n",
    "                b = self.biases[ix] if self.with_bias else 0\n",
    "                if self.sparse_features:\n",
    "                    hidden = adj_norm @ torch.spmm(hidden, w) + b\n",
    "                else:\n",
    "                    hidden = adj_norm @ hidden @ w + b\n",
    "                if self.with_relu:\n",
    "                    hidden = F.relu(hidden)\n",
    "\n",
    "            output = F.log_softmax(hidden, dim=1)\n",
    "            loss_labeled = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "\n",
    "            weight_grads = torch.autograd.grad(loss_labeled, self.weights, create_graph=True)\n",
    "            self.w_velocities = [self.momentum * v + g for v, g in zip(self.w_velocities, weight_grads)]\n",
    "            if self.with_bias:\n",
    "                bias_grads = torch.autograd.grad(loss_labeled, self.biases, create_graph=True)\n",
    "                self.b_velocities = [self.momentum * v + g for v, g in zip(self.b_velocities, bias_grads)]\n",
    "\n",
    "            self.weights = [w - self.lr * v for w, v in zip(self.weights, self.w_velocities)]\n",
    "            if self.with_bias:\n",
    "                self.biases = [b - self.lr * v for b, v in zip(self.biases, self.b_velocities)]\n",
    "\n",
    "    def get_meta_grad(self, features, adj_norm, idx_train, idx_unlabeled, labels, labels_self_training):\n",
    "\n",
    "        hidden = features\n",
    "        for ix, w in enumerate(self.weights):\n",
    "            b = self.biases[ix] if self.with_bias else 0\n",
    "            if self.sparse_features:\n",
    "                hidden = adj_norm @ torch.spmm(hidden, w) + b\n",
    "            else:\n",
    "                hidden = adj_norm @ hidden @ w + b\n",
    "            if self.with_relu:\n",
    "                hidden = F.relu(hidden)\n",
    "\n",
    "        output = F.log_softmax(hidden, dim=1)\n",
    "\n",
    "        loss_labeled = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        loss_unlabeled = F.nll_loss(output[idx_unlabeled], labels_self_training[idx_unlabeled])\n",
    "        loss_test_val = F.nll_loss(output[idx_unlabeled], labels[idx_unlabeled])\n",
    "\n",
    "        if self.lambda_ == 1:\n",
    "            attack_loss = loss_labeled\n",
    "        elif self.lambda_ == 0:\n",
    "            attack_loss = loss_unlabeled\n",
    "        else:\n",
    "            attack_loss = self.lambda_ * loss_labeled + (1 - self.lambda_) * loss_unlabeled\n",
    "\n",
    "        print('GCN loss on unlabled data: {}'.format(loss_test_val.item()))\n",
    "        print('GCN acc on unlabled data: {}'.format(utils.accuracy(output[idx_unlabeled], labels[idx_unlabeled]).item()))\n",
    "        print('attack loss: {}'.format(attack_loss.item()))\n",
    "\n",
    "        adj_grad, feature_grad = None, None\n",
    "        if self.attack_structure:\n",
    "            adj_grad = torch.autograd.grad(attack_loss, self.adj_changes, retain_graph=True)[0]\n",
    "        if self.attack_features:\n",
    "            feature_grad = torch.autograd.grad(attack_loss, self.feature_changes, retain_graph=True)[0]\n",
    "        return adj_grad, feature_grad\n",
    "\n",
    "    def attack(self, ori_features, ori_adj, labels, idx_train, idx_unlabeled, n_perturbations, ll_constraint=True, ll_cutoff=0.004):\n",
    "        \"\"\"Generate n_perturbations on the input graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ori_features :\n",
    "            Original (unperturbed) node feature matrix\n",
    "        ori_adj :\n",
    "            Original (unperturbed) adjacency matrix\n",
    "        labels :\n",
    "            node labels\n",
    "        idx_train :\n",
    "            node training indices\n",
    "        idx_unlabeled:\n",
    "            unlabeled nodes indices\n",
    "        n_perturbations : int\n",
    "            Number of perturbations on the input graph. Perturbations could\n",
    "            be edge removals/additions or feature removals/additions.\n",
    "        ll_constraint: bool\n",
    "            whether to exert the likelihood ratio test constraint\n",
    "        ll_cutoff : float\n",
    "            The critical value for the likelihood ratio test of the power law distributions.\n",
    "            See the Chi square distribution with one degree of freedom. Default value 0.004\n",
    "            corresponds to a p-value of roughly 0.95. It would be ignored if `ll_constraint`\n",
    "            is False.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.sparse_features = sp.issparse(ori_features)\n",
    "        ori_adj, ori_features, labels = utils.to_tensor(ori_adj, ori_features, labels, device=self.device)\n",
    "        labels_self_training = self.self_training_label(labels, idx_train)\n",
    "        modified_adj = ori_adj\n",
    "        modified_features = ori_features\n",
    "\n",
    "        for i in tqdm(range(n_perturbations), desc=\"Perturbing graph\"):\n",
    "            if self.attack_structure:\n",
    "                modified_adj = self.get_modified_adj(ori_adj)\n",
    "\n",
    "            if self.attack_features:\n",
    "                modified_features = ori_features + self.feature_changes\n",
    "\n",
    "            adj_norm = utils.normalize_adj_tensor(modified_adj)\n",
    "            self.inner_train(modified_features, adj_norm, idx_train, idx_unlabeled, labels)\n",
    "\n",
    "            adj_grad, feature_grad = self.get_meta_grad(modified_features, adj_norm, idx_train, idx_unlabeled, labels, labels_self_training)\n",
    "\n",
    "            adj_meta_score = torch.tensor(0.0).to(self.device)\n",
    "            feature_meta_score = torch.tensor(0.0).to(self.device)\n",
    "            if self.attack_structure:\n",
    "                adj_meta_score = self.get_adj_score(adj_grad, modified_adj, ori_adj, ll_constraint, ll_cutoff)\n",
    "            if self.attack_features:\n",
    "                feature_meta_score = self.get_feature_score(feature_grad, modified_features)\n",
    "\n",
    "            if adj_meta_score.max() >= feature_meta_score.max():\n",
    "                adj_meta_argmax = torch.argmax(adj_meta_score)\n",
    "                row_idx, col_idx = utils.unravel_index(adj_meta_argmax, ori_adj.shape)\n",
    "                self.adj_changes.data[row_idx][col_idx] += (-2 * modified_adj[row_idx][col_idx] + 1)\n",
    "                self.adj_changes.data[col_idx][row_idx] += (-2 * modified_adj[row_idx][col_idx] + 1)\n",
    "            else:\n",
    "                feature_meta_argmax = torch.argmax(feature_meta_score)\n",
    "                row_idx, col_idx = utils.unravel_index(feature_meta_argmax, ori_features.shape)\n",
    "                self.feature_changes.data[row_idx][col_idx] += (-2 * modified_features[row_idx][col_idx] + 1)\n",
    "\n",
    "        if self.attack_structure:\n",
    "            self.modified_adj = self.get_modified_adj(ori_adj).detach()\n",
    "        if self.attack_features:\n",
    "            self.modified_features = self.get_modified_features(ori_features).detach()\n",
    "\n",
    "\n",
    "class MetaApprox(BaseMeta):\n",
    "    \"\"\"Approximated version of Meta Attack. Adversarial Attacks on\n",
    "    Graph Neural Networks via Meta Learning, ICLR 2019.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> from deeprobust.graph.data import Dataset\n",
    "    >>> from deeprobust.graph.defense import GCN\n",
    "    >>> from deeprobust.graph.global_attack import MetaApprox\n",
    "    >>> from deeprobust.graph.utils import preprocess\n",
    "    >>> data = Dataset(root='/tmp/', name='cora')\n",
    "    >>> adj, features, labels = data.adj, data.features, data.labels\n",
    "    >>> adj, features, labels = preprocess(adj, features, labels, preprocess_adj=False) # conver to tensor\n",
    "    >>> idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "    >>> idx_unlabeled = np.union1d(idx_val, idx_test)\n",
    "    >>> # Setup Surrogate model\n",
    "    >>> surrogate = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                    nhid=16, dropout=0, with_relu=False, with_bias=False, device='cpu').to('cpu')\n",
    "    >>> surrogate.fit(features, adj, labels, idx_train, idx_val, patience=30)\n",
    "    >>> # Setup Attack Model\n",
    "    >>> model = MetaApprox(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "            attack_structure=True, attack_features=False, device='cpu', lambda_=0).to('cpu')\n",
    "    >>> # Attack\n",
    "    >>> model.attack(features, adj, labels, idx_train, idx_unlabeled, n_perturbations=10, ll_constraint=True)\n",
    "    >>> modified_adj = model.modified_adj\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, nnodes, feature_shape=None, attack_structure=True, attack_features=False, device='cpu', with_bias=False, lambda_=0.5, train_iters=100, lr=0.01):\n",
    "\n",
    "        super(MetaApprox, self).__init__(model, nnodes, feature_shape, lambda_, attack_structure, attack_features, device)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.train_iters = train_iters\n",
    "        self.adj_meta_grad = None\n",
    "        self.features_meta_grad = None\n",
    "        if self.attack_structure:\n",
    "            self.adj_grad_sum = torch.zeros(nnodes, nnodes).to(device)\n",
    "        if self.attack_features:\n",
    "            self.feature_grad_sum = torch.zeros(feature_shape).to(device)\n",
    "\n",
    "        self.with_bias = with_bias\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        previous_size = self.nfeat\n",
    "        for ix, nhid in enumerate(self.hidden_sizes):\n",
    "            weight = Parameter(torch.FloatTensor(previous_size, nhid).to(device))\n",
    "            bias = Parameter(torch.FloatTensor(nhid).to(device))\n",
    "            previous_size = nhid\n",
    "\n",
    "            self.weights.append(weight)\n",
    "            self.biases.append(bias)\n",
    "\n",
    "        output_weight = Parameter(torch.FloatTensor(previous_size, self.nclass).to(device))\n",
    "        output_bias = Parameter(torch.FloatTensor(self.nclass).to(device))\n",
    "        self.weights.append(output_weight)\n",
    "        self.biases.append(output_bias)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.weights + self.biases, lr=lr) # , weight_decay=5e-4)\n",
    "        self._initialize()\n",
    "\n",
    "    def _initialize(self):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            # w.data.fill_(1)\n",
    "            # b.data.fill_(1)\n",
    "            stdv = 1. / math.sqrt(w.size(1))\n",
    "            w.data.uniform_(-stdv, stdv)\n",
    "            b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.weights + self.biases, lr=self.lr)\n",
    "\n",
    "    def inner_train(self, features, modified_adj, idx_train, idx_unlabeled, labels, labels_self_training):\n",
    "        adj_norm = utils.normalize_adj_tensor(modified_adj)\n",
    "        for j in range(self.train_iters):\n",
    "            # hidden = features\n",
    "            # for w, b in zip(self.weights, self.biases):\n",
    "            #     if self.sparse_features:\n",
    "            #         hidden = adj_norm @ torch.spmm(hidden, w) + b\n",
    "            #     else:\n",
    "            #         hidden = adj_norm @ hidden @ w + b\n",
    "            #     if self.with_relu:\n",
    "            #         hidden = F.relu(hidden)\n",
    "\n",
    "            hidden = features\n",
    "            for ix, w in enumerate(self.weights):\n",
    "                b = self.biases[ix] if self.with_bias else 0\n",
    "                if self.sparse_features:\n",
    "                    hidden = adj_norm @ torch.spmm(hidden, w) + b\n",
    "                else:\n",
    "                    hidden = adj_norm @ hidden @ w + b\n",
    "                if self.with_relu:\n",
    "                    hidden = F.relu(hidden)\n",
    "\n",
    "            output = F.log_softmax(hidden, dim=1)\n",
    "            loss_labeled = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "            loss_unlabeled = F.nll_loss(output[idx_unlabeled], labels_self_training[idx_unlabeled])\n",
    "\n",
    "            if self.lambda_ == 1:\n",
    "                attack_loss = loss_labeled\n",
    "            elif self.lambda_ == 0:\n",
    "                attack_loss = loss_unlabeled\n",
    "            else:\n",
    "                attack_loss = self.lambda_ * loss_labeled + (1 - self.lambda_) * loss_unlabeled\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_labeled.backward(retain_graph=True)\n",
    "\n",
    "            if self.attack_structure:\n",
    "                self.adj_changes.grad.zero_()\n",
    "                self.adj_grad_sum += torch.autograd.grad(attack_loss, self.adj_changes, retain_graph=True)[0]\n",
    "            if self.attack_features:\n",
    "                self.feature_changes.grad.zero_()\n",
    "                self.feature_grad_sum += torch.autograd.grad(attack_loss, self.feature_changes, retain_graph=True)[0]\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "        loss_test_val = F.nll_loss(output[idx_unlabeled], labels[idx_unlabeled])\n",
    "        print('GCN loss on unlabled data: {}'.format(loss_test_val.item()))\n",
    "        print('GCN acc on unlabled data: {}'.format(utils.accuracy(output[idx_unlabeled], labels[idx_unlabeled]).item()))\n",
    "\n",
    "\n",
    "    def attack(self, ori_features, ori_adj, labels, idx_train, idx_unlabeled, n_perturbations, ll_constraint=True, ll_cutoff=0.004):\n",
    "        \"\"\"Generate n_perturbations on the input graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ori_features :\n",
    "            Original (unperturbed) node feature matrix\n",
    "        ori_adj :\n",
    "            Original (unperturbed) adjacency matrix\n",
    "        labels :\n",
    "            node labels\n",
    "        idx_train :\n",
    "            node training indices\n",
    "        idx_unlabeled:\n",
    "            unlabeled nodes indices\n",
    "        n_perturbations : int\n",
    "            Number of perturbations on the input graph. Perturbations could\n",
    "            be edge removals/additions or feature removals/additions.\n",
    "        ll_constraint: bool\n",
    "            whether to exert the likelihood ratio test constraint\n",
    "        ll_cutoff : float\n",
    "            The critical value for the likelihood ratio test of the power law distributions.\n",
    "            See the Chi square distribution with one degree of freedom. Default value 0.004\n",
    "            corresponds to a p-value of roughly 0.95. It would be ignored if `ll_constraint`\n",
    "            is False.\n",
    "\n",
    "        \"\"\"\n",
    "        ori_adj, ori_features, labels = utils.to_tensor(ori_adj, ori_features, labels, device=self.device)\n",
    "        labels_self_training = self.self_training_label(labels, idx_train)\n",
    "        self.sparse_features = sp.issparse(ori_features)\n",
    "        modified_adj = ori_adj\n",
    "        modified_features = ori_features\n",
    "\n",
    "        for i in tqdm(range(n_perturbations), desc=\"Perturbing graph\"):\n",
    "            self._initialize()\n",
    "\n",
    "            if self.attack_structure:\n",
    "                modified_adj = self.get_modified_adj(ori_adj)\n",
    "                self.adj_grad_sum.data.fill_(0)\n",
    "            if self.attack_features:\n",
    "                modified_features = ori_features + self.feature_changes\n",
    "                self.feature_grad_sum.data.fill_(0)\n",
    "\n",
    "            self.inner_train(modified_features, modified_adj, idx_train, idx_unlabeled, labels, labels_self_training)\n",
    "\n",
    "            adj_meta_score = torch.tensor(0.0).to(self.device)\n",
    "            feature_meta_score = torch.tensor(0.0).to(self.device)\n",
    "\n",
    "            if self.attack_structure:\n",
    "                adj_meta_score = self.get_adj_score(self.adj_grad_sum, modified_adj, ori_adj, ll_constraint, ll_cutoff)\n",
    "            if self.attack_features:\n",
    "                feature_meta_score = self.get_feature_score(self.feature_grad_sum, modified_features)\n",
    "\n",
    "            if adj_meta_score.max() >= feature_meta_score.max():\n",
    "                adj_meta_argmax = torch.argmax(adj_meta_score)\n",
    "                row_idx, col_idx = utils.unravel_index(adj_meta_argmax, ori_adj.shape)\n",
    "                self.adj_changes.data[row_idx][col_idx] += (-2 * modified_adj[row_idx][col_idx] + 1)\n",
    "                self.adj_changes.data[col_idx][row_idx] += (-2 * modified_adj[row_idx][col_idx] + 1)\n",
    "            else:\n",
    "                feature_meta_argmax = torch.argmax(feature_meta_score)\n",
    "                row_idx, col_idx = utils.unravel_index(feature_meta_argmax, ori_features.shape)\n",
    "                self.feature_changes.data[row_idx][col_idx] += (-2 * modified_features[row_idx][col_idx] + 1)\n",
    "\n",
    "        if self.attack_structure:\n",
    "            self.modified_adj = self.get_modified_adj(ori_adj).detach()\n",
    "        if self.attack_features:\n",
    "            self.modified_features = self.get_modified_features(ori_features).detach()\n"
   ]
  }
 ]
}